{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('E:\\\\Python\\Data\\\\1000 educational data_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>math_score</th>\n",
       "      <th>science_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>final_marks</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>religion</th>\n",
       "      <th>geographic_info</th>\n",
       "      <th>teaching_method</th>\n",
       "      <th>teaching_materials</th>\n",
       "      <th>technology_use</th>\n",
       "      <th>passed</th>\n",
       "      <th>attendance_rate</th>\n",
       "      <th>class_participation</th>\n",
       "      <th>assignment_completed</th>\n",
       "      <th>presentation_marks</th>\n",
       "      <th>group_work</th>\n",
       "      <th>field_work</th>\n",
       "      <th>graduation_status</th>\n",
       "      <th>scholarship</th>\n",
       "      <th>online_learning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.53</td>\n",
       "      <td>52.05</td>\n",
       "      <td>37.35</td>\n",
       "      <td>323.10</td>\n",
       "      <td>0</td>\n",
       "      <td>Christian</td>\n",
       "      <td>Rural</td>\n",
       "      <td>constructivist</td>\n",
       "      <td>No use</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.47</td>\n",
       "      <td>23.83</td>\n",
       "      <td>23.88</td>\n",
       "      <td>292.62</td>\n",
       "      <td>0</td>\n",
       "      <td>Buddhist</td>\n",
       "      <td>Urban</td>\n",
       "      <td>modern</td>\n",
       "      <td>No use</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.05</td>\n",
       "      <td>64.08</td>\n",
       "      <td>50.39</td>\n",
       "      <td>325.49</td>\n",
       "      <td>1</td>\n",
       "      <td>Buddhist</td>\n",
       "      <td>Urban</td>\n",
       "      <td>constructivist</td>\n",
       "      <td>digital resource</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62.65</td>\n",
       "      <td>50.01</td>\n",
       "      <td>26.38</td>\n",
       "      <td>428.42</td>\n",
       "      <td>0</td>\n",
       "      <td>Others</td>\n",
       "      <td>Rural</td>\n",
       "      <td>traditional</td>\n",
       "      <td>hands-on</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58.67</td>\n",
       "      <td>30.86</td>\n",
       "      <td>51.66</td>\n",
       "      <td>327.54</td>\n",
       "      <td>0</td>\n",
       "      <td>Buddhist</td>\n",
       "      <td>Urban</td>\n",
       "      <td>constructivist</td>\n",
       "      <td>No use</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   math_score  science_score  reading_score  final_marks  employment_status  \\\n",
       "0       68.53          52.05          37.35       323.10                  0   \n",
       "1       43.47          23.83          23.88       292.62                  0   \n",
       "2       61.05          64.08          50.39       325.49                  1   \n",
       "3       62.65          50.01          26.38       428.42                  0   \n",
       "4       58.67          30.86          51.66       327.54                  0   \n",
       "\n",
       "    religion geographic_info teaching_method teaching_materials  \\\n",
       "0  Christian           Rural  constructivist             No use   \n",
       "1   Buddhist           Urban          modern             No use   \n",
       "2   Buddhist           Urban  constructivist   digital resource   \n",
       "3     Others           Rural     traditional           hands-on   \n",
       "4   Buddhist           Urban  constructivist             No use   \n",
       "\n",
       "   technology_use  passed  attendance_rate  class_participation  \\\n",
       "0               0       1               70                    2   \n",
       "1               0       1               44                    9   \n",
       "2               1       1               79                    8   \n",
       "3               1       1               43                    2   \n",
       "4               0       1               90                    3   \n",
       "\n",
       "   assignment_completed  presentation_marks  group_work  field_work  \\\n",
       "0                     0                   4           2          13   \n",
       "1                     3                   8           1           7   \n",
       "2                     8                   5           8          17   \n",
       "3                     6                   7           7           6   \n",
       "4                     4                  10           3           2   \n",
       "\n",
       "   graduation_status  scholarship  online_learning  \n",
       "0                  1            1                0  \n",
       "1                  0            1                0  \n",
       "2                  1            0                1  \n",
       "3                  0            0                0  \n",
       "4                  1            0                1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      math_score  science_score  reading_score  final_marks  employment_status  \\\n",
       "0         68.53          52.05          37.35       323.10                  0   \n",
       "1         43.47          23.83          23.88       292.62                  0   \n",
       "2         61.05          64.08          50.39       325.49                  1   \n",
       "3         62.65          50.01          26.38       428.42                  0   \n",
       "4         58.67          30.86          51.66       327.54                  0   \n",
       "..          ...            ...            ...          ...                ...   \n",
       "995       55.46          55.98          60.31       347.90                  0   \n",
       "996       63.45          62.00          29.93       300.11                  1   \n",
       "997       44.20          54.68          47.80       374.07                  0   \n",
       "998       64.60          64.39          17.29       425.04                  1   \n",
       "999       39.88          60.49          77.12       335.81                  0   \n",
       "\n",
       "      religion geographic_info teaching_method teaching_materials  \\\n",
       "0    Christian           Rural  constructivist             No use   \n",
       "1     Buddhist           Urban          modern             No use   \n",
       "2     Buddhist           Urban  constructivist   digital resource   \n",
       "3       Others           Rural     traditional           hands-on   \n",
       "4     Buddhist           Urban  constructivist             No use   \n",
       "..         ...             ...             ...                ...   \n",
       "995     Others           Rural          modern           hands-on   \n",
       "996     Others           Urban          modern           hands-on   \n",
       "997     Others           Rural          modern           hands-on   \n",
       "998  Christian           Urban          modern           hands-on   \n",
       "999     Others           Rural     traditional             No use   \n",
       "\n",
       "     technology_use  passed  attendance_rate  class_participation  \\\n",
       "0                 0       1               70                    2   \n",
       "1                 0       1               44                    9   \n",
       "2                 1       1               79                    8   \n",
       "3                 1       1               43                    2   \n",
       "4                 0       1               90                    3   \n",
       "..              ...     ...              ...                  ...   \n",
       "995               0       1               92                   10   \n",
       "996               0       1               43                    2   \n",
       "997               1       1               49                    8   \n",
       "998               0       1               65                    6   \n",
       "999               0       1               79                    2   \n",
       "\n",
       "     assignment_completed  presentation_marks  group_work  field_work  \\\n",
       "0                       0                   4           2          13   \n",
       "1                       3                   8           1           7   \n",
       "2                       8                   5           8          17   \n",
       "3                       6                   7           7           6   \n",
       "4                       4                  10           3           2   \n",
       "..                    ...                 ...         ...         ...   \n",
       "995                     0                   5           0           9   \n",
       "996                     5                   4           7           5   \n",
       "997                     3                   3           1          13   \n",
       "998                     3                   5           3           8   \n",
       "999                     0                   5           3          17   \n",
       "\n",
       "     graduation_status  scholarship  online_learning  \n",
       "0                    1            1                0  \n",
       "1                    0            1                0  \n",
       "2                    1            0                1  \n",
       "3                    0            0                0  \n",
       "4                    1            0                1  \n",
       "..                 ...          ...              ...  \n",
       "995                  1            1                1  \n",
       "996                  1            0                0  \n",
       "997                  1            0                1  \n",
       "998                  1            0                1  \n",
       "999                  1            0                0  \n",
       "\n",
       "[1000 rows x 20 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>math_score</th>\n",
       "      <th>science_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>final_marks</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>technology_use</th>\n",
       "      <th>passed</th>\n",
       "      <th>attendance_rate</th>\n",
       "      <th>class_participation</th>\n",
       "      <th>assignment_completed</th>\n",
       "      <th>presentation_marks</th>\n",
       "      <th>group_work</th>\n",
       "      <th>field_work</th>\n",
       "      <th>graduation_status</th>\n",
       "      <th>scholarship</th>\n",
       "      <th>online_learning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.689740</td>\n",
       "      <td>50.731780</td>\n",
       "      <td>49.941560</td>\n",
       "      <td>350.912240</td>\n",
       "      <td>0.477000</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>70.792000</td>\n",
       "      <td>5.275000</td>\n",
       "      <td>5.266000</td>\n",
       "      <td>5.040000</td>\n",
       "      <td>4.996000</td>\n",
       "      <td>10.294000</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.543000</td>\n",
       "      <td>0.486000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.297087</td>\n",
       "      <td>12.041751</td>\n",
       "      <td>20.056374</td>\n",
       "      <td>52.255651</td>\n",
       "      <td>0.499721</td>\n",
       "      <td>0.500225</td>\n",
       "      <td>0.176088</td>\n",
       "      <td>17.537397</td>\n",
       "      <td>3.177967</td>\n",
       "      <td>3.145018</td>\n",
       "      <td>3.160124</td>\n",
       "      <td>3.093793</td>\n",
       "      <td>6.048483</td>\n",
       "      <td>0.500106</td>\n",
       "      <td>0.498397</td>\n",
       "      <td>0.500054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>183.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>44.537500</td>\n",
       "      <td>42.715000</td>\n",
       "      <td>35.792500</td>\n",
       "      <td>316.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54.930000</td>\n",
       "      <td>51.035000</td>\n",
       "      <td>50.615000</td>\n",
       "      <td>350.105000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>65.725000</td>\n",
       "      <td>58.782500</td>\n",
       "      <td>63.855000</td>\n",
       "      <td>386.225000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>85.110000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        math_score  science_score  reading_score  final_marks  \\\n",
       "count  1000.000000    1000.000000    1000.000000  1000.000000   \n",
       "mean     54.689740      50.731780      49.941560   350.912240   \n",
       "std      15.297087      12.041751      20.056374    52.255651   \n",
       "min      10.000000      10.000000       1.000000   183.850000   \n",
       "25%      44.537500      42.715000      35.792500   316.450000   \n",
       "50%      54.930000      51.035000      50.615000   350.105000   \n",
       "75%      65.725000      58.782500      63.855000   386.225000   \n",
       "max      95.000000      85.110000     100.000000   500.000000   \n",
       "\n",
       "       employment_status  technology_use       passed  attendance_rate  \\\n",
       "count        1000.000000     1000.000000  1000.000000      1000.000000   \n",
       "mean            0.477000        0.495000     0.968000        70.792000   \n",
       "std             0.499721        0.500225     0.176088        17.537397   \n",
       "min             0.000000        0.000000     0.000000        40.000000   \n",
       "25%             0.000000        0.000000     1.000000        55.750000   \n",
       "50%             0.000000        0.000000     1.000000        71.000000   \n",
       "75%             1.000000        1.000000     1.000000        86.000000   \n",
       "max             1.000000        1.000000     1.000000       100.000000   \n",
       "\n",
       "       class_participation  assignment_completed  presentation_marks  \\\n",
       "count          1000.000000           1000.000000         1000.000000   \n",
       "mean              5.275000              5.266000            5.040000   \n",
       "std               3.177967              3.145018            3.160124   \n",
       "min               0.000000              0.000000            0.000000   \n",
       "25%               2.000000              3.000000            2.000000   \n",
       "50%               5.000000              5.000000            5.000000   \n",
       "75%               8.000000              8.000000            8.000000   \n",
       "max              10.000000             10.000000           10.000000   \n",
       "\n",
       "        group_work   field_work  graduation_status  scholarship  \\\n",
       "count  1000.000000  1000.000000        1000.000000  1000.000000   \n",
       "mean      4.996000    10.294000           0.512000     0.543000   \n",
       "std       3.093793     6.048483           0.500106     0.498397   \n",
       "min       0.000000     0.000000           0.000000     0.000000   \n",
       "25%       2.000000     5.000000           0.000000     0.000000   \n",
       "50%       5.000000    10.000000           1.000000     1.000000   \n",
       "75%       8.000000    15.000000           1.000000     1.000000   \n",
       "max      10.000000    20.000000           1.000000     1.000000   \n",
       "\n",
       "       online_learning  \n",
       "count      1000.000000  \n",
       "mean          0.486000  \n",
       "std           0.500054  \n",
       "min           0.000000  \n",
       "25%           0.000000  \n",
       "50%           0.000000  \n",
       "75%           1.000000  \n",
       "max           1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['math_score', 'science_score', 'reading_score', 'final_marks',\n",
       "       'employment_status', 'religion', 'geographic_info', 'teaching_method',\n",
       "       'teaching_materials', 'technology_use', 'passed', 'attendance_rate',\n",
       "       'class_participation', 'assignment_completed', 'presentation_marks',\n",
       "       'group_work', 'field_work', 'graduation_status', 'scholarship',\n",
       "       'online_learning'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.view of 0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "995    1\n",
       "996    1\n",
       "997    1\n",
       "998    1\n",
       "999    1\n",
       "Name: passed, Length: 1000, dtype: int64>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['passed'].view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     1\n",
       "     ..\n",
       "95    1\n",
       "96    1\n",
       "97    1\n",
       "98    0\n",
       "99    1\n",
       "Name: passed, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['passed'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900    1\n",
       "901    1\n",
       "902    1\n",
       "903    1\n",
       "904    1\n",
       "      ..\n",
       "995    1\n",
       "996    1\n",
       "997    1\n",
       "998    1\n",
       "999    1\n",
       "Name: passed, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['passed'].tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['passed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "math_score  science_score  reading_score  final_marks  employment_status  religion   geographic_info  teaching_method  teaching_materials  technology_use  passed  attendance_rate  class_participation  assignment_completed  presentation_marks  group_work  field_work  graduation_status  scholarship  online_learning\n",
       "22.46       48.85          85.29          211.74       0                  Buddhist   Rural            traditional      No use              0               0       62               4                    7                     0                   10          2           0                  0            1                  1\n",
       "29.15       45.65          35.81          213.41       0                  Others     Rural            modern           hands-on            1               0       86               1                    4                     4                   4           12          0                  1            1                  1\n",
       "80.42       41.57          67.04          236.51       1                  Buddhist   Urban            constructivist   No use              1               0       47               9                    6                     9                   4           9           0                  1            1                  1\n",
       "78.15       56.64          25.80          244.84       1                  Hindu      Urban            traditional      hands-on            1               0       50               7                    9                     7                   2           1           0                  1            1                  1\n",
       "77.06       61.21          64.37          232.63       1                  Buddhist   Rural            traditional      hands-on            0               0       63               3                    8                     2                   2           8           0                  1            0                  1\n",
       "72.16       53.50          11.94          245.75       1                  Others     Rural            traditional      digital resource    1               0       82               6                    5                     4                   9           7           0                  1            0                  1\n",
       "70.73       51.62          28.37          220.85       0                  Christian  Urban            constructivist   hands-on            1               0       88               9                    0                     4                   8           13          0                  0            0                  1\n",
       "69.44       63.00          16.74          246.34       1                  Christian  Urban            constructivist   No use              0               0       96               7                    7                     4                   9           10          0                  0            1                  1\n",
       "67.17       64.45          15.34          227.40       1                  Buddhist   Urban            traditional      digital resource    1               0       83               9                    0                     9                   3           0           0                  1            1                  1\n",
       "64.92       59.74          9.59           188.06       0                  Others     Rural            constructivist   digital resource    1               0       80               10                   9                     10                  1           16          0                  1            0                  1\n",
       "62.46       42.89          13.87          217.97       1                  Christian  Rural            traditional      No use              0               0       100              2                    2                     2                   8           10          0                  1            1                  1\n",
       "61.29       44.83          46.43          237.87       0                  Buddhist   Rural            constructivist   hands-on            0               0       100              6                    1                     8                   3           2           1                  1            0                  1\n",
       "60.72       23.92          59.97          192.96       0                  Hindu      Rural            traditional      digital resource    1               0       76               3                    1                     1                   7           3           0                  0            0                  1\n",
       "60.25       82.92          47.82          239.42       1                  Others     Rural            constructivist   hands-on            1               0       58               0                    9                     4                   2           0           1                  1            1                  1\n",
       "59.03       35.93          57.30          204.14       0                  Hindu      Urban            modern           No use              1               0       53               5                    2                     9                   10          12          1                  1            1                  1\n",
       "56.39       54.30          36.53          242.37       0                  Buddhist   Urban            traditional      hands-on            1               0       44               0                    4                     6                   10          5           0                  1            0                  1\n",
       "56.27       43.88          49.67          245.95       1                  Christian  Rural            modern           No use              1               0       98               0                    2                     7                   6           10          1                  1            1                  1\n",
       "56.07       72.87          52.45          248.80       1                  Others     Urban            constructivist   digital resource    1               0       73               6                    2                     8                   7           17          0                  1            1                  1\n",
       "53.47       58.72          78.56          212.51       1                  Buddhist   Urban            traditional      hands-on            0               0       61               6                    7                     5                   8           19          1                  1            1                  1\n",
       "51.55       54.99          31.30          210.61       0                  Hindu      Urban            modern           digital resource    1               0       97               10                   1                     5                   8           13          0                  0            0                  1\n",
       "51.02       52.82          26.07          249.13       1                  Others     Rural            constructivist   digital resource    1               0       71               4                    6                     6                   6           16          0                  0            0                  1\n",
       "50.69       51.34          60.61          246.97       0                  Others     Rural            modern           No use              1               0       72               6                    3                     5                   4           17          0                  0            0                  1\n",
       "49.40       49.21          43.44          228.27       1                  Others     Urban            modern           digital resource    0               0       93               3                    9                     2                   8           16          1                  0            0                  1\n",
       "49.17       62.75          57.22          189.80       0                  Buddhist   Urban            traditional      No use              1               0       76               3                    2                     5                   6           10          0                  1            0                  1\n",
       "48.70       27.79          67.55          237.80       0                  Christian  Rural            constructivist   hands-on            0               0       81               6                    1                     7                   5           13          1                  1            0                  1\n",
       "46.17       40.88          51.45          242.78       1                  Christian  Rural            modern           No use              1               0       99               9                    5                     9                   2           9           1                  1            1                  1\n",
       "41.68       48.62          71.20          222.16       1                  Christian  Urban            modern           No use              1               0       74               7                    9                     1                   7           8           0                  0            1                  1\n",
       "40.76       54.20          65.36          246.32       1                  Others     Urban            modern           hands-on            1               0       80               5                    9                     10                  4           0           0                  0            1                  1\n",
       "37.67       52.61          25.35          237.77       0                  Others     Rural            constructivist   No use              1               0       98               4                    9                     3                   9           4           0                  0            1                  1\n",
       "35.35       34.26          29.93          222.26       0                  Others     Urban            traditional      No use              1               0       51               8                    5                     10                  10          2           0                  0            0                  1\n",
       "32.92       24.01          97.24          216.89       1                  Others     Rural            modern           No use              0               0       97               3                    4                     4                   8           7           1                  0            0                  1\n",
       "85.79       42.27          53.22          183.85       0                  Hindu      Urban            traditional      No use              0               0       89               9                    8                     7                   7           15          0                  1            1                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['passed'] == 0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, RepeatedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 1), (1000,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['final_marks']]\n",
    "y = df['passed']\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing for Numerical Data \n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = Pipeline(steps = [('preprocessor', numeric_transformer), ('classifier', SVC())])\n",
    "logistic_model = Pipeline(steps = [('preprocessor', numeric_transformer), ('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1) (200, 1) (800,) (200,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)  # Predicting the test set results\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm) # Calculating the accuracy of the model\n",
    "print(y_pred_svm)\n",
    "print(svm_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluation Logistic Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "0.995\n"
     ]
    }
   ],
   "source": [
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic = logistic_model.predict(X_test)  # Predicting the test set results\n",
    "logistic_accuracy = accuracy_score(y_test, y_pred_logistic) # Calculating the accuracy of the model \n",
    "print(y_pred_logistic)\n",
    "print(logistic_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99 1.   1.   1.   1.   1.   0.99 1.   1.   1.  ]\n"
     ]
    }
   ],
   "source": [
    "svm_score = cross_val_score(svm_model, X, y, cv=10)\n",
    "print(svm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_mean_score = np.mean(svm_score)\n",
    "svm_mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99, 0.98, 0.98, 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.98])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_score = cross_val_score(logistic_model, X, y, cv = 10)\n",
    "logistic_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.993"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_mean_score = np.mean(logistic_score)\n",
    "logistic_mean_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "svm_score_skf = cross_val_score(svm_model, X, y, cv=skf)\n",
    "svm_mean_score_skf = np.mean(svm_score_skf)\n",
    "print(svm_score_skf)\n",
    "print(svm_mean_score_skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98 1.   1.   1.   0.99 0.99 0.99 0.98 0.99 1.  ]\n",
      "0.992\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "logistic_score_skf = cross_val_score(logistic_model, X, y, cv=skf)\n",
    "logistic_mean_score_skf = np.mean(logistic_score_skf)\n",
    "print(logistic_score_skf)\n",
    "print(logistic_mean_score_skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.   1.   1.   1.   0.99 1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      " 1.   1.   1.   1.   0.99 1.   1.   1.   1.   1.   0.99 1.   1.   1.\n",
      " 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      " 1.   1.   1.   1.   1.   0.99 1.   1.   1.   1.   1.   0.99 0.99 1.\n",
      " 0.99 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   0.98 1.\n",
      " 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      " 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      " 1.   1.  ]\n",
      "0.9991\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits=10, n_repeats=10, random_state=42)\n",
    "svm_score_rkf = cross_val_score(svm_model, X, y, cv=rkf)\n",
    "svm_mean_score_rkf = np.mean(svm_score_rkf)\n",
    "print(svm_score_rkf)\n",
    "print(svm_mean_score_rkf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98 1.   0.99 1.   1.   0.96 1.   1.   0.98 1.   1.   1.   0.98 1.\n",
      " 0.98 0.99 0.99 0.99 0.99 1.   1.   1.   1.   1.   1.   0.99 0.99 1.\n",
      " 0.97 0.98 0.98 1.   0.99 1.   0.99 0.97 1.   1.   1.   1.   0.99 0.98\n",
      " 1.   0.98 1.   1.   0.99 1.   0.99 0.99 1.   0.99 1.   0.96 1.   1.\n",
      " 0.97 1.   0.99 1.   0.98 1.   0.99 1.   0.97 0.99 1.   1.   1.   0.99\n",
      " 1.   0.99 0.98 1.   1.   0.99 0.99 0.98 1.   0.99 0.99 0.99 0.99 0.99\n",
      " 1.   1.   0.97 1.   0.99 1.   0.99 0.99 1.   1.   1.   0.99 1.   0.95\n",
      " 0.99 1.  ]\n",
      "0.9919\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits=10, n_repeats=10, random_state=42)\n",
    "logistic_score_rkf = cross_val_score(logistic_model, X, y, cv=rkf)\n",
    "logistic_mean_score_rkf = np.mean(logistic_score_rkf)\n",
    "print(logistic_score_rkf)\n",
    "print(logistic_mean_score_rkf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling all into a DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Method  SVM Accuracy  \\\n",
      "0                  Train-Test Split        1.0000   \n",
      "1           K-Fold Cross Validation        0.9980   \n",
      "2  StratifiedKFold Cross Validation        1.0000   \n",
      "3    RepeatedKFold Cross Validation        0.9991   \n",
      "\n",
      "   Logistic Regression Accuracy  \n",
      "0                        0.9950  \n",
      "1                        0.9930  \n",
      "2                        0.9920  \n",
      "3                        0.9919  \n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({'Method':\n",
    "    ['Train-Test Split', \n",
    "     'K-Fold Cross Validation',\n",
    "     'StratifiedKFold Cross Validation',\n",
    "     'RepeatedKFold Cross Validation'],\n",
    "    'SVM Accuracy': [\n",
    "        svm_accuracy,\n",
    "        svm_mean_score,\n",
    "        svm_mean_score_skf,\n",
    "        svm_mean_score_rkf\n",
    "    ],\n",
    "    'Logistic Regression Accuracy': [\n",
    "        logistic_accuracy, \n",
    "        logistic_mean_score,\n",
    "        logistic_mean_score_skf,\n",
    "        logistic_mean_score_rkf\n",
    "    ]})\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave One Out Cross Validation (LOOCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.999\n"
     ]
    }
   ],
   "source": [
    "loo =LeaveOneOut()\n",
    "svm_score_loo = cross_val_score(svm_model, X, y, cv = loo)\n",
    "svm_mean_score_loo = np.mean(svm_score_loo)\n",
    "print(svm_score_loo)\n",
    "print(svm_mean_score_loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.992\n"
     ]
    }
   ],
   "source": [
    "#For logistic Regression\n",
    "loo =LeaveOneOut()\n",
    "logistic_score_loo = cross_val_score(logistic_model, X, y, cv = loo)\n",
    "logistic_mean_score_loo = np.mean(logistic_score_loo)\n",
    "print(logistic_score_loo)\n",
    "print(logistic_mean_score_loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(final_marks    385.57\n",
       " Name: 100, dtype: float64,\n",
       " 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[100], y.iloc[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>math_score</th>\n",
       "      <th>science_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>final_marks</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>religion</th>\n",
       "      <th>geographic_info</th>\n",
       "      <th>teaching_method</th>\n",
       "      <th>teaching_materials</th>\n",
       "      <th>technology_use</th>\n",
       "      <th>passed</th>\n",
       "      <th>attendance_rate</th>\n",
       "      <th>class_participation</th>\n",
       "      <th>assignment_completed</th>\n",
       "      <th>presentation_marks</th>\n",
       "      <th>group_work</th>\n",
       "      <th>field_work</th>\n",
       "      <th>graduation_status</th>\n",
       "      <th>scholarship</th>\n",
       "      <th>online_learning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.53</td>\n",
       "      <td>52.05</td>\n",
       "      <td>37.35</td>\n",
       "      <td>323.10</td>\n",
       "      <td>0</td>\n",
       "      <td>Christian</td>\n",
       "      <td>Rural</td>\n",
       "      <td>constructivist</td>\n",
       "      <td>No use</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.47</td>\n",
       "      <td>23.83</td>\n",
       "      <td>23.88</td>\n",
       "      <td>292.62</td>\n",
       "      <td>0</td>\n",
       "      <td>Buddhist</td>\n",
       "      <td>Urban</td>\n",
       "      <td>modern</td>\n",
       "      <td>No use</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.05</td>\n",
       "      <td>64.08</td>\n",
       "      <td>50.39</td>\n",
       "      <td>325.49</td>\n",
       "      <td>1</td>\n",
       "      <td>Buddhist</td>\n",
       "      <td>Urban</td>\n",
       "      <td>constructivist</td>\n",
       "      <td>digital resource</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62.65</td>\n",
       "      <td>50.01</td>\n",
       "      <td>26.38</td>\n",
       "      <td>428.42</td>\n",
       "      <td>0</td>\n",
       "      <td>Others</td>\n",
       "      <td>Rural</td>\n",
       "      <td>traditional</td>\n",
       "      <td>hands-on</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58.67</td>\n",
       "      <td>30.86</td>\n",
       "      <td>51.66</td>\n",
       "      <td>327.54</td>\n",
       "      <td>0</td>\n",
       "      <td>Buddhist</td>\n",
       "      <td>Urban</td>\n",
       "      <td>constructivist</td>\n",
       "      <td>No use</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   math_score  science_score  reading_score  final_marks  employment_status  \\\n",
       "0       68.53          52.05          37.35       323.10                  0   \n",
       "1       43.47          23.83          23.88       292.62                  0   \n",
       "2       61.05          64.08          50.39       325.49                  1   \n",
       "3       62.65          50.01          26.38       428.42                  0   \n",
       "4       58.67          30.86          51.66       327.54                  0   \n",
       "\n",
       "    religion geographic_info teaching_method teaching_materials  \\\n",
       "0  Christian           Rural  constructivist             No use   \n",
       "1   Buddhist           Urban          modern             No use   \n",
       "2   Buddhist           Urban  constructivist   digital resource   \n",
       "3     Others           Rural     traditional           hands-on   \n",
       "4   Buddhist           Urban  constructivist             No use   \n",
       "\n",
       "   technology_use  passed  attendance_rate  class_participation  \\\n",
       "0               0       1               70                    2   \n",
       "1               0       1               44                    9   \n",
       "2               1       1               79                    8   \n",
       "3               1       1               43                    2   \n",
       "4               0       1               90                    3   \n",
       "\n",
       "   assignment_completed  presentation_marks  group_work  field_work  \\\n",
       "0                     0                   4           2          13   \n",
       "1                     3                   8           1           7   \n",
       "2                     8                   5           8          17   \n",
       "3                     6                   7           7           6   \n",
       "4                     4                  10           3           2   \n",
       "\n",
       "   graduation_status  scholarship  online_learning  \n",
       "0                  1            1                0  \n",
       "1                  0            1                0  \n",
       "2                  1            0                1  \n",
       "3                  0            0                0  \n",
       "4                  1            0                1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'E:\\\\Python\\Data\\\\1000 educational data_final.csv'\n",
    "df = pd.read_csv(file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 4), (1000,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['final_marks', 'math_score', 'reading_score', 'science_score']]\n",
    "y = df['passed']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intializing the One Leave Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeaveOneOut()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loo = LeaveOneOut()\n",
    "loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_accuracy = []\n",
    "logistic_accuracy = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in loo.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
      " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
      " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
      " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
      " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
      " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
      " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
      " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
      " 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683\n",
      " 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701\n",
      " 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719\n",
      " 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737\n",
      " 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755\n",
      " 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773\n",
      " 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791\n",
      " 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809\n",
      " 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827\n",
      " 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845\n",
      " 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863\n",
      " 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881\n",
      " 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899\n",
      " 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917\n",
      " 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935\n",
      " 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953\n",
      " 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971\n",
      " 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989\n",
      " 990 991 992 993 994 995 996 997 998]\n"
     ]
    }
   ],
   "source": [
    "print(train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([999])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.28915144, -0.96862562,  1.35578045,  0.81077104]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in loo.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index] \n",
    "    svm_model = SVC() \n",
    "    svm_model.fit(X_train, y_train) \n",
    "    y_pred_svm = svm_model.predict(X_test)\n",
    "    svm_accuracy.append(accuracy_score(y_test, y_pred_svm))\n",
    "print(svm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9901283316880553"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_mean_score = np.mean(svm_accuracy)\n",
    "svm_mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in loo.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index] \n",
    "    logistic_model = LogisticRegression()\n",
    "    logistic_model.fit(X_train, y_train) \n",
    "    y_pred_logistic = logistic_model.predict(X_test)\n",
    "    logistic_accuracy.append(accuracy_score(y_test, y_pred_logistic))\n",
    "print(logistic_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9940119760479041"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_mean_score = np.mean(logistic_accuracy)\n",
    "logistic_mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Mean Accuracy: 0.99\n",
      "Logistic Regression Mean Accuracy: 0.994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file = 'E:\\\\Python\\Data\\\\1000 educational data_final.csv'\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Define the features and target variable\n",
    "X = df[['final_marks', 'math_score', 'reading_score', 'science_score']]\n",
    "y = df['passed']\n",
    "\n",
    "# Scale the numerical data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize LeaveOneOut cross-validator\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Lists to store accuracy for each iteration\n",
    "svm_accuracies = []\n",
    "logistic_accuracies = []\n",
    "\n",
    "# Perform LOOCV\n",
    "for train_index, test_index in loo.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Train and evaluate SVM\n",
    "    svm_model = SVC()\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_pred_svm = svm_model.predict(X_test)\n",
    "    svm_accuracies.append(accuracy_score(y_test, y_pred_svm))\n",
    "    \n",
    "    # Train and evaluate Logistic Regression\n",
    "    logistic_model = LogisticRegression(max_iter=1000)\n",
    "    logistic_model.fit(X_train, y_train)\n",
    "    y_pred_logistic = logistic_model.predict(X_test)\n",
    "    logistic_accuracies.append(accuracy_score(y_test, y_pred_logistic))\n",
    "\n",
    "# Calculate mean accuracy\n",
    "svm_mean_accuracy = np.mean(svm_accuracies)\n",
    "logistic_mean_accuracy = np.mean(logistic_accuracies)\n",
    "\n",
    "print(\"SVM Mean Accuracy:\", svm_mean_accuracy)\n",
    "print(\"Logistic Regression Mean Accuracy:\", logistic_mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.28915144, -0.96862562,  1.35578045,  0.81077104]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([999])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing Specific Test Value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy for test sample: 1.0\n",
      "Logistic Regression Accuracy for test sample: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file = 'E:\\\\Python\\\\Data\\\\1000 educational data_final.csv'  # Update the path as necessary\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Define the features and target variable\n",
    "X = df[['final_marks', 'math_score', 'reading_score', 'science_score']]\n",
    "y = df['passed']\n",
    "\n",
    "# Scale the numerical data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Specify the index of the test sample\n",
    "test_index = 0  # Replace with the index you want to test\n",
    "\n",
    "# Split the data\n",
    "X_test = X_scaled[test_index].reshape(1, -1)\n",
    "y_test = y.iloc[test_index]\n",
    "\n",
    "X_train = np.delete(X_scaled, test_index, axis=0)\n",
    "y_train = y.drop(index=test_index)\n",
    "\n",
    "# Train and evaluate SVM\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "svm_accuracy = accuracy_score([y_test], y_pred_svm)\n",
    "\n",
    "# Train and evaluate Logistic Regression\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "logistic_accuracy = accuracy_score([y_test], y_pred_logistic)\n",
    "\n",
    "print(\"SVM Accuracy for test sample:\", svm_accuracy)\n",
    "print(\"Logistic Regression Accuracy for test sample:\", logistic_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy for test sample: 1.0\n",
      "Logistic Regression Accuracy for test sample: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file = 'E:\\\\Python\\\\Data\\\\1000 educational data_final.csv'  # Update the path as necessary\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Define the features and target variable\n",
    "X = df[['final_marks', 'math_score', 'reading_score', 'science_score']]\n",
    "y = df['passed']\n",
    "\n",
    "# Scale the numerical data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Specify the index of the test sample\n",
    "test_index = 2  # Replace with the index you want to test\n",
    "\n",
    "# Split the data\n",
    "X_test = X_scaled[test_index].reshape(1, -1)\n",
    "y_test = y.iloc[test_index]\n",
    "\n",
    "X_train = np.delete(X_scaled, test_index, axis=0)\n",
    "y_train = y.drop(index=test_index)\n",
    "\n",
    "# Train and evaluate SVM\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "svm_accuracy = accuracy_score([y_test], y_pred_svm)\n",
    "\n",
    "# Train and evaluate Logistic Regression\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "logistic_accuracy = accuracy_score([y_test], y_pred_logistic)\n",
    "\n",
    "print(\"SVM Accuracy for test sample:\", svm_accuracy)\n",
    "print(\"Logistic Regression Accuracy for test sample:\", logistic_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy for test sample: 1.0\n",
      "Logistic Regression Accuracy for test sample: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file = 'E:\\\\Python\\\\Data\\\\1000 educational data_final.csv'  # Update the path as necessary\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Define the features and target variable\n",
    "X = df[['final_marks', 'math_score', 'reading_score', 'science_score']]\n",
    "y = df['passed']\n",
    "\n",
    "# Scale the numerical data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Specify the index of the test sample\n",
    "test_index = 999  # Replace with the index you want to test\n",
    "\n",
    "# Split the data\n",
    "X_test = X_scaled[test_index].reshape(1, -1)\n",
    "y_test = y.iloc[test_index]\n",
    "\n",
    "X_train = np.delete(X_scaled, test_index, axis=0)\n",
    "y_train = y.drop(index=test_index)\n",
    "\n",
    "# Train and evaluate SVM\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "svm_accuracy = accuracy_score([y_test], y_pred_svm)\n",
    "\n",
    "# Train and evaluate Logistic Regression\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "logistic_accuracy = accuracy_score([y_test], y_pred_logistic)\n",
    "\n",
    "print(\"SVM Accuracy for test sample:\", svm_accuracy)\n",
    "print(\"Logistic Regression Accuracy for test sample:\", logistic_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy for test sample: 1.0\n",
      "Logistic Regression Accuracy for test sample: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file = 'E:\\\\Python\\\\Data\\\\1000 educational data_final.csv'  # Update the path as necessary\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Define the features and target variable\n",
    "X = df[['final_marks', 'math_score', 'reading_score', 'science_score']]\n",
    "y = df['passed']\n",
    "\n",
    "# Scale the numerical data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Specify the index of the test sample\n",
    "test_index = 998  # Replace with the index you want to test\n",
    "\n",
    "# Split the data\n",
    "X_test = X_scaled[test_index].reshape(1, -1)\n",
    "y_test = y.iloc[test_index]\n",
    "\n",
    "X_train = np.delete(X_scaled, test_index, axis=0)\n",
    "y_train = y.drop(index=test_index)\n",
    "\n",
    "# Train and evaluate SVM\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "svm_accuracy = accuracy_score([y_test], y_pred_svm)\n",
    "\n",
    "# Train and evaluate Logistic Regression\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "logistic_accuracy = accuracy_score([y_test], y_pred_logistic)\n",
    "\n",
    "print(\"SVM Accuracy for test sample:\", svm_accuracy)\n",
    "print(\"Logistic Regression Accuracy for test sample:\", logistic_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
